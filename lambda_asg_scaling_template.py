#!/usr/bin/env python3
"""
Auto Scaling Group (ASG) Scaling Lambda Function
Handles scheduled scaling of ASG instances based on EventBridge events
Supports both scale-up and scale-down operations
Template version with injectable parameters
Generated on: {{current_date}} {{current_time}} UTC
Created by: {{current_user}}
"""

import json
import boto3
import logging
import os
import time
from datetime import datetime, timedelta, timezone
from typing import Dict, Any, Optional
from botocore.exceptions import ClientError, BotoCoreError

# Configure enhanced logging
logger = logging.getLogger()
logger.setLevel(logging.INFO)


# Create custom formatter for better log structure
class CustomFormatter(logging.Formatter):
    def format(self, record):
        timestamp = datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S UTC')
        level = record.levelname
        message = record.getMessage()
        return f"[{timestamp}] [{level}] {message}"


# Apply custom formatter to existing handlers
for handler in logger.handlers:
    handler.setFormatter(CustomFormatter())


class ASGScaler:
    def __init__(self):
        self.logger = logger
        self.start_time = None
        self.execution_stats = {
            'instances_before': 0,
            'instances_after': 0,
            'scaling_operations': 0,
            'errors_encountered': 0,
            'warnings_issued': 0
        }

    def log_execution_start(self, asg_name, direction, ist_time):
        """Log execution start with detailed context"""
        self.start_time = time.time()
        self.logger.info("=" * 80)
        self.logger.info("[START] ASG SCALING LAMBDA - EXECUTION START")
        self.logger.info("=" * 80)
        self.logger.info(f"[DATE] Execution Time: {datetime.utcnow().isoformat()}Z")
        self.logger.info(f"[TARGET] Target ASG: {asg_name}")
        self.logger.info(f"ğŸ“ˆ Scaling Direction: {direction.upper()}")
        self.logger.info(f"[TIME] IST Time: {ist_time}")
        self.logger.info(f"ğŸ‘¤ Generated By: {{current_user}}")
        self.logger.info(f"[LOG] Template Generated: {{current_date}} {{current_time}} UTC")
        self.logger.info("=" * 80)

    def log_execution_end(self, success=True):
        """Log execution end with summary statistics"""
        execution_time = time.time() - self.start_time if self.start_time else 0
        self.logger.info("=" * 80)
        self.logger.info("ğŸ ASG SCALING LAMBDA - EXECUTION END")
        self.logger.info("=" * 80)
        self.logger.info(f"[TIMER]  Total Execution Time: {execution_time:.2f} seconds")
        self.logger.info(f"[STATS] Instances Before: {self.execution_stats['instances_before']}")
        self.logger.info(f"[STATS] Instances After: {self.execution_stats['instances_after']}")
        self.logger.info(f"ğŸ“ˆ Scaling Operations: {self.execution_stats['scaling_operations']}")
        self.logger.info(f"[ERROR] Errors Encountered: {self.execution_stats['errors_encountered']}")
        self.logger.info(f"[WARN]  Warnings Issued: {self.execution_stats['warnings_issued']}")
        self.logger.info(f"[OK] Execution Status: {'SUCCESS' if success else 'FAILED'}")
        self.logger.info("=" * 80)

    def calculate_ist_time(self):
        """Calculate current IST time with logging"""
        self.logger.info("[TIME] IST time not provided in event, calculating current IST time...")

        try:
            # Calculate current IST time (UTC + 5:30)
            ist_timezone = timezone(timedelta(hours=5, minutes=30))
            current_ist = datetime.now(ist_timezone)
            ist_time = current_ist.strftime('%I:%M %p IST')

            self.logger.info(f"[OK] Current IST time calculated: {ist_time}")
            return ist_time

        except Exception as e:
            self.logger.warning(f"[WARN]  Error calculating IST time: {str(e)} - using UTC time")
            self.execution_stats['warnings_issued'] += 1
            utc_time = datetime.utcnow().strftime('%I:%M %p UTC')
            return utc_time

    def create_asg_client(self, region=None):
        """Create ASG client with enhanced logging and validation"""
        self.logger.info("[CONFIG] Initializing AWS Auto Scaling client...")

        try:
            if region:
                asg_client = boto3.client('autoscaling', region_name=region)
                self.logger.info(f"   Region: {region}")
            else:
                asg_client = boto3.client('autoscaling')
                self.logger.info(f"   Region: Using default AWS region")

            # Test connectivity
            self.logger.info("[TEST] Testing AWS client connectivity...")
            try:
                sts_client = boto3.client('sts', region_name=region) if region else boto3.client('sts')
                identity = sts_client.get_caller_identity()
                self.logger.info(f"[OK] AWS connectivity verified - Account: {identity.get('Account')}")
                self.logger.info(f"   User/Role ARN: {identity.get('Arn')}")
            except Exception as e:
                self.logger.warning(f"[WARN]  Could not verify AWS identity: {str(e)}")
                self.execution_stats['warnings_issued'] += 1

            return asg_client

        except Exception as e:
            self.logger.error(f"[ERROR] Failed to create ASG client: {str(e)}")
            self.execution_stats['errors_encountered'] += 1
            raise

    def get_asg_configuration(self, asg_client, asg_name):
        """Get current ASG configuration with enhanced logging"""
        self.logger.info(f"[LIST] Retrieving ASG configuration for: {asg_name}")

        try:
            response = asg_client.describe_auto_scaling_groups(
                AutoScalingGroupNames=[asg_name]
            )

            if not response['AutoScalingGroups']:
                self.logger.error(f"[ERROR] ASG {asg_name} not found")
                raise ValueError(f"ASG {asg_name} not found")

            asg = response['AutoScalingGroups'][0]

            # Extract current configuration
            current_config = {
                'desired_capacity': asg.get('DesiredCapacity', 0),
                'min_size': asg.get('MinSize', 0),
                'max_size': asg.get('MaxSize', 0),
                'instances': asg.get('Instances', []),
                'availability_zones': asg.get('AvailabilityZones', []),
                'vpc_zone_identifier': asg.get('VPCZoneIdentifier', ''),
                'health_check_type': asg.get('HealthCheckType', 'EC2'),
                'default_cooldown': asg.get('DefaultCooldown', 300),
                'created_time': asg.get('CreatedTime', 'unknown'),
                'service_linked_role_arn': asg.get('ServiceLinkedRoleARN', 'unknown')
            }

            # Count instances by state
            instance_states = {}
            for instance in current_config['instances']:
                state = instance.get('LifecycleState', 'Unknown')
                instance_states[state] = instance_states.get(state, 0) + 1

            self.logger.info(f"[OK] ASG configuration retrieved:")
            self.logger.info(f"   â”œâ”€â”€ Current desired capacity: {current_config['desired_capacity']}")
            self.logger.info(f"   â”œâ”€â”€ Min size: {current_config['min_size']}")
            self.logger.info(f"   â”œâ”€â”€ Max size: {current_config['max_size']}")
            self.logger.info(f"   â”œâ”€â”€ Total instances: {len(current_config['instances'])}")
            self.logger.info(f"   â”œâ”€â”€ Instance states: {instance_states}")
            self.logger.info(f"   â”œâ”€â”€ Availability zones: {len(current_config['availability_zones'])}")
            self.logger.info(f"   â”œâ”€â”€ Health check type: {current_config['health_check_type']}")
            self.logger.info(f"   â””â”€â”€ Default cooldown: {current_config['default_cooldown']}s")

            # Store current instance count for statistics
            self.execution_stats['instances_before'] = current_config['desired_capacity']

            return current_config

        except ClientError as e:
            error_code = e.response['Error']['Code']
            if error_code == 'ResourceNotFoundException':
                self.logger.error(f"[ERROR] ASG {asg_name} not found")
            elif error_code == 'AccessDeniedException':
                self.logger.error(f"[ERROR] Access denied to ASG {asg_name} - check IAM permissions")
            else:
                self.logger.error(f"[ERROR] AWS API error: {error_code} - {e.response['Error']['Message']}")
            self.execution_stats['errors_encountered'] += 1
            raise
        except Exception as e:
            self.logger.error(f"[ERROR] Unexpected error retrieving ASG configuration: {str(e)}")
            self.execution_stats['errors_encountered'] += 1
            raise

    def calculate_new_capacity(self, current_config, direction):
        """Calculate new desired capacity based on scaling direction"""
        current_desired = current_config['desired_capacity']
        min_size = current_config['min_size']
        max_size = current_config['max_size']

        self.logger.info(f"ğŸ§® Calculating new capacity...")
        self.logger.info(f"   â”œâ”€â”€ Current configuration: desired={current_desired}, min={min_size}, max={max_size}")
        self.logger.info(f"   â””â”€â”€ Scaling direction: {direction}")

        if direction.lower() == 'up':
            # Scale up logic: set to at least min_size, or 1 if min_size is 0
            new_desired = max(min_size, 1) if current_desired == 0 else max(current_desired, min_size)
            action_description = 'scaled up'

            # Ensure we don't exceed max_size
            if new_desired > max_size:
                new_desired = max_size
                self.logger.warning(f"[WARN]  Desired capacity capped at max_size: {max_size}")
                self.execution_stats['warnings_issued'] += 1

        elif direction.lower() == 'down':
            # Scale down logic: set to 0
            new_desired = 0
            action_description = 'scaled down'

        else:
            # Unknown direction
            self.logger.error(f"[ERROR] Unknown scaling direction: {direction}")
            raise ValueError(f"Unknown scaling direction: {direction}")

        self.logger.info(f"[OK] New capacity calculated:")
        self.logger.info(f"   â”œâ”€â”€ New desired capacity: {new_desired}")
        self.logger.info(f"   â”œâ”€â”€ Action: {action_description}")
        self.logger.info(f"   â””â”€â”€ Change: {current_desired} â†’ {new_desired} ({new_desired - current_desired:+d})")

        return new_desired, action_description

    def update_asg_capacity(self, asg_client, asg_name, new_desired, current_desired):
        """Update ASG desired capacity with enhanced logging"""
        self.logger.info(f"ğŸ”„ Updating ASG desired capacity...")

        try:
            # Check if update is needed
            if new_desired == current_desired:
                self.logger.info(f"[SKIP]  No capacity change needed - ASG already at desired capacity: {current_desired}")
                return {
                    'updated': False,
                    'reason': 'No change needed',
                    'previous_capacity': current_desired,
                    'new_capacity': new_desired
                }

            self.logger.info(f"   â”œâ”€â”€ Updating ASG: {asg_name}")
            self.logger.info(f"   â”œâ”€â”€ From: {current_desired} instances")
            self.logger.info(f"   â”œâ”€â”€ To: {new_desired} instances")
            self.logger.info(f"   â””â”€â”€ Honor cooldown: False")

            # Perform the capacity update
            asg_client.set_desired_capacity(
                AutoScalingGroupName=asg_name,
                DesiredCapacity=new_desired,
                HonorCooldown=False
            )

            self.logger.info(f"[OK] ASG capacity update completed successfully")
            self.execution_stats['scaling_operations'] += 1
            self.execution_stats['instances_after'] = new_desired

            return {
                'updated': True,
                'reason': 'Capacity updated successfully',
                'previous_capacity': current_desired,
                'new_capacity': new_desired
            }

        except ClientError as e:
            error_code = e.response['Error']['Code']
            error_message = e.response['Error']['Message']

            if error_code == 'ScalingActivityInProgressFault':
                self.logger.error(f"[ERROR] Scaling activity already in progress for ASG {asg_name}")
            elif error_code == 'ResourceContentionFault':
                self.logger.error(f"[ERROR] Resource contention while updating ASG {asg_name}")
            elif error_code == 'ValidationError':
                self.logger.error(f"[ERROR] Validation error: {error_message}")
            else:
                self.logger.error(f"[ERROR] AWS API error: {error_code} - {error_message}")

            self.execution_stats['errors_encountered'] += 1
            raise
        except Exception as e:
            self.logger.error(f"[ERROR] Unexpected error updating ASG capacity: {str(e)}")
            self.execution_stats['errors_encountered'] += 1
            raise

    def scale_asg(self, asg_name, direction, ist_time, region=None):
        """Main ASG scaling logic with comprehensive logging"""
        self.log_execution_start(asg_name, direction, ist_time)

        try:
            # Create ASG client
            asg_client = self.create_asg_client(region)

            # Get current ASG configuration
            current_config = self.get_asg_configuration(asg_client, asg_name)

            # Calculate new capacity
            new_desired, action_description = self.calculate_new_capacity(current_config, direction)

            # Update ASG capacity
            update_result = self.update_asg_capacity(
                asg_client,
                asg_name,
                new_desired,
                current_config['desired_capacity']
            )

            # Prepare success response
            self.log_execution_end(success=True)

            response_body = {
                'success': True,
                'message': f"ASG {asg_name} {action_description} to {new_desired} instances",
                'timestamp': datetime.utcnow().isoformat() + 'Z',
                'asg_name': asg_name,
                'direction': direction,
                'ist_time': ist_time,
                'capacity_change': {
                    'previous': current_config['desired_capacity'],
                    'new': new_desired,
                    'change': new_desired - current_config['desired_capacity']
                },
                'update_result': update_result,
                'execution_stats': self.execution_stats,
                'processed_by': 'asg-scaling-lambda',
                'processed_by_user': '{{current_user}}',
                'generated_on': '{{current_date}} {{current_time}} UTC'
            }

            return {
                'statusCode': 200,
                'body': json.dumps(response_body, default=str)
            }

        except Exception as e:
            error_msg = str(e)
            self.logger.error(f"[BOOM] ASG scaling operation failed: {error_msg}")
            self.log_execution_end(success=False)

            error_response = {
                'success': False,
                'error': f'Error scaling ASG: {error_msg}',
                'asg_name': asg_name,
                'direction': direction,
                'timestamp': datetime.utcnow().isoformat() + 'Z',
                'execution_stats': self.execution_stats
            }

            return {
                'statusCode': 500,
                'body': json.dumps(error_response)
            }


# Create global instance
scaler = ASGScaler()


def lambda_handler(event, context):
    """
    AWS Lambda entry point for ASG scaling

    Template variables that will be injected:
    - {{ASG_NAME}}: Auto Scaling Group name
    - {{DIRECTION}}: Scaling direction (up/down)
    - {{current_user}}: User who generated this function
    - {{current_date}}: Date when function was generated
    - {{current_time}}: Time when function was generated
    """
    try:
        logger.info(f"[START] ASG Scaling Lambda function invoked")
        logger.info(f"[ROUNDPIN] Function ARN: {context.invoked_function_arn}")
        logger.info(f"[DATE] Template generated: {{current_date}} {{current_time}} UTC")
        logger.info(f"ğŸ‘¤ Generated by user: {{current_user}}")
        logger.info(f"[TIMER]  Remaining execution time: {context.get_remaining_time_in_millis()}ms")
        logger.info(f"[INSTANCE] Memory limit: {context.memory_limit_in_mb}MB")

        # Log event (safely)
        logger.info(f"ğŸ“¥ Event received: {json.dumps(event, indent=2)}")

        # Get configuration from template injection or event
        asg_name = '{{ASG_NAME}}' if '{{ASG_NAME}}' != '{{ASG_NAME}}' else event.get('asg_name') or os.environ.get(
            'ASG_NAME')
        direction = '{{DIRECTION}}' if '{{DIRECTION}}' != '{{DIRECTION}}' else event.get('direction') or os.environ.get(
            'SCALING_DIRECTION', 'up')
        region = event.get('region') or os.environ.get('AWS_REGION')

        # Get IST time - if not provided, calculate current IST time
        ist_time = event.get('ist_time')
        if not ist_time or ist_time == 'unknown time':
            ist_time = scaler.calculate_ist_time()

        logger.info(f"[CONFIG] Configuration resolved:")
        logger.info(f"   â”œâ”€â”€ ASG Name: {asg_name or 'NOT SPECIFIED'}")
        logger.info(f"   â”œâ”€â”€ Direction: {direction}")
        logger.info(f"   â”œâ”€â”€ Region: {region or 'DEFAULT'}")
        logger.info(f"   â””â”€â”€ IST Time: {ist_time}")

        # Validate required parameters
        if not asg_name:
            error_msg = 'ASG name is required in template injection, event payload, or ASG_NAME environment variable'
            logger.error(f"[ERROR] Validation failed: {error_msg}")
            return {
                'statusCode': 400,
                'body': json.dumps({
                    'success': False,
                    'error': error_msg,
                    'timestamp': datetime.utcnow().isoformat() + 'Z'
                })
            }

        if direction not in ['up', 'down']:
            error_msg = f'Invalid scaling direction: {direction}. Must be "up" or "down"'
            logger.error(f"[ERROR] Validation failed: {error_msg}")
            return {
                'statusCode': 400,
                'body': json.dumps({
                    'success': False,
                    'error': error_msg,
                    'asg_name': asg_name,
                    'timestamp': datetime.utcnow().isoformat() + 'Z'
                })
            }

        logger.info(f"[OK] Validation passed - proceeding with scaling operation")

        # Run the scaling logic
        result = scaler.scale_asg(asg_name, direction, ist_time, region)

        logger.info(f"[PARTY] Lambda execution completed with status: {result['statusCode']}")
        return result

    except Exception as e:
        logger.error(f"[BOOM] Lambda handler failed with unexpected error: {str(e)}")
        return {
            'statusCode': 500,
            'body': json.dumps({
                'success': False,
                'error': f'Lambda execution failed: {str(e)}',
                'timestamp': datetime.utcnow().isoformat() + 'Z'
            })
        }


"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
[LIST] SAMPLE EVENT STRUCTURES FOR TESTING
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

1. ğŸŒ… MORNING SCALE-UP EVENT (Basic):
{
    "asg_name": "my-web-servers-asg",
    "direction": "up",
    "ist_time": "8:30 AM IST"
}

2. ğŸŒ™ EVENING SCALE-DOWN EVENT (Basic):
{
    "asg_name": "my-web-servers-asg", 
    "direction": "down",
    "ist_time": "6:30 PM IST"
}

3. [START] SCALE-UP WITH REGION (Production):
{
    "asg_name": "prod-web-servers-asg",
    "direction": "up",
    "region": "us-east-1",
    "ist_time": "8:00 AM IST"
}

4. ğŸ“‰ SCALE-DOWN WITH REGION (Production):
{
    "asg_name": "prod-web-servers-asg",
    "direction": "down", 
    "region": "us-east-1",
    "ist_time": "7:00 PM IST"
}

5. [TEST] TESTING EVENT (Development Environment):
{
    "asg_name": "dev-test-asg",
    "direction": "up",
    "region": "us-west-2",
    "ist_time": "10:00 AM IST"
}

6. [CONFIG] MAINTENANCE SCALE-DOWN EVENT:
{
    "asg_name": "maintenance-workers-asg",
    "direction": "down",
    "ist_time": "2:00 AM IST"
}

7. [FAST] BURST SCALING EVENT (High Traffic):
{
    "asg_name": "burst-capacity-asg",
    "direction": "up",
    "region": "us-east-1",
    "ist_time": "11:00 AM IST"
}

8. [REGION] CROSS-REGION EVENT (EU West):
{
    "asg_name": "eu-web-servers-asg",
    "direction": "up",
    "region": "eu-west-1",
    "ist_time": "2:30 PM IST"
}

9. [ALERT] EMERGENCY SCALE-DOWN EVENT:
{
    "asg_name": "emergency-shutdown-asg",
    "direction": "down",
    "ist_time": "11:45 PM IST"
}

10. [MAILBOX] MINIMAL EVENT (Tests Template Injection):
{
    "direction": "up"
}

11. [ERROR] ERROR TEST EVENT (Invalid Direction):
{
    "asg_name": "test-asg",
    "direction": "invalid",
    "ist_time": "9:00 AM IST"
}

12. ğŸ”„ SPOT INSTANCE ASG SCALING:
{
    "asg_name": "spot-instances-asg",
    "direction": "up",
    "region": "ap-southeast-1", 
    "ist_time": "9:30 AM IST"
}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
[LOG] EVENTBRIDGE SCHEDULED EVENT EXAMPLES
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

EventBridge Rule for Morning Scale-Up (8:30 AM IST = 3:00 AM UTC):
{
    "Rules": [
        {
            "Name": "asg-morning-scale-up",
            "ScheduleExpression": "cron(0 3 * * ? *)",
            "Targets": [
                {
                    "Id": "1",
                    "Arn": "arn:aws:lambda:us-east-1:123456789012:function:asg-scaling-function",
                    "Input": "{\"asg_name\": \"my-web-servers-asg\", \"direction\": \"up\", \"ist_time\": \"8:30 AM IST\"}"
                }
            ]
        }
    ]
}

EventBridge Rule for Evening Scale-Down (6:30 PM IST = 1:00 PM UTC):
{
    "Rules": [
        {
            "Name": "asg-evening-scale-down",
            "ScheduleExpression": "cron(0 13 * * ? *)",
            "Targets": [
                {
                    "Id": "1", 
                    "Arn": "arn:aws:lambda:us-east-1:123456789012:function:asg-scaling-function",
                    "Input": "{\"asg_name\": \"my-web-servers-asg\", \"direction\": \"down\", \"ist_time\": \"6:30 PM IST\"}"
                }
            ]
        }
    ]
}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
[CONFIG] ENVIRONMENT VARIABLES (Fallback Configuration)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ASG_NAME: my-web-servers-asg
SCALING_DIRECTION: up (default if not specified)
AWS_REGION: us-east-1

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
[STATS] TEMPLATE INJECTION VARIABLES
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

{{ASG_NAME}}: Will be replaced with actual Auto Scaling Group name
{{DIRECTION}}: Will be replaced with scaling direction (up/down)
{{current_user}}: User who generated this function
{{current_date}}: Date when function was generated (YYYY-MM-DD)
{{current_time}}: Time when function was generated (HH:MM:SS)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""


def main():
    """
    Local testing function - simulates Lambda execution with template values
    """
    print("[TEST] LOCAL TEST MODE ACTIVATED")
    print("=" * 80)
    print(f"[DATE] Template generated: {{current_date}} {{current_time}} UTC")
    print(f"ğŸ‘¤ Generated by: {{current_user}}")
    print("=" * 80)

    # Test events
    scale_up_event = {
        "asg_name": "test-asg",
        "direction": "up",
        "ist_time": "8:30 AM IST",
        "region": "us-east-1"
    }

    scale_down_event = {
        "asg_name": "test-asg",
        "direction": "down",
        "ist_time": "6:30 PM IST",
        "region": "us-east-1"
    }

    # Mock Lambda context
    class MockContext:
        def __init__(self):
            self.function_name = 'asg-scaling-function'
            self.function_version = '$LATEST'
            self.invoked_function_arn = 'arn:aws:lambda:{{region}}:123456789012:function:asg-scaling-function'
            self.memory_limit_in_mb = '128'
            self.remaining_time_in_millis = 30000
            self.log_group_name = '/aws/lambda/asg-scaling-function'
            self.log_stream_name = '{{current_date}}/[$LATEST]test'

        def get_remaining_time_in_millis(self):
            return self.remaining_time_in_millis

    context = MockContext()

    try:
        print("\n[START] Testing SCALE UP operation...")
        result = lambda_handler(scale_up_event, context)
        print(f"Status Code: {result['statusCode']}")
        if result.get('body'):
            body = json.loads(result['body'])
            print(json.dumps(body, indent=2))

        print("\n[START] Testing SCALE DOWN operation...")
        result = lambda_handler(scale_down_event, context)
        print(f"Status Code: {result['statusCode']}")
        if result.get('body'):
            body = json.loads(result['body'])
            print(json.dumps(body, indent=2))

        print("\n[OK] Local testing completed!")

    except Exception as e:
        print(f"[BOOM] Local test failed with error: {str(e)}")


if __name__ == "__main__":
    main()